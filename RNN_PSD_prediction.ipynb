{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPO3SLMs4nhNudH+L5yZB3Y",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/barauna-lo/Colored_Noise/blob/main/RNN_PSD_prediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_gqPalciLgWK",
        "outputId": "32d8dfa0-5a06-4bd8-a5c8-4d13c13da94f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting colorednoise\n",
            "  Downloading colorednoise-2.1.0-py3-none-any.whl (4.5 kB)\n",
            "Requirement already satisfied: numpy>=1.17.0 in /usr/local/lib/python3.7/dist-packages (from colorednoise) (1.21.6)\n",
            "Installing collected packages: colorednoise\n",
            "Successfully installed colorednoise-2.1.0\n"
          ]
        }
      ],
      "source": [
        "!pip install colorednoise\n",
        "import colorednoise as cn\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "import seaborn as sns\n",
        "sns.set_style('darkgrid')\n",
        "\n",
        "from keras import Sequential\n",
        "from keras.layers import Conv2D, Flatten, Dense, LSTM, GRU, RNN,SimpleRNN, InputLayer,Conv1D, add, Reshape, Flatten\n",
        "from sklearn.preprocessing import MinMaxScaler, MaxAbsScaler\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn import preprocessing\n",
        "#from datetime import datetime # for put the time info in each plot          #https://stackoverflow.com/questions/415511/how-to-get-the-current-time-in-python\n",
        "import time as time"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "$$\n",
        "Ftt = \\sum a_i \\sin(2k\\pi)+ i b_i \\cos(2k\\pi)\\\\\n",
        "PSD = (a_i + b_i)(a_i-b_i)\\\\\n",
        "PSD = a^2 + b^2\\\\\n",
        "S_h = {\\sum PSD_i \\log(PSD_i) \\over \\log\\left(\\frac{1}{N}\\right)}\n",
        "$$\n",
        "\n",
        "were $b$ in the imaginarius parte"
      ],
      "metadata": {
        "id": "ccP2Tg-BZ8Ni"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Functions"
      ],
      "metadata": {
        "id": "-1a6_v0savYM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def entropyShannon(data,norm=True):\n",
        "  '''\n",
        "  Calculate the Shannon spectrum entropy for a given dataseta\n",
        "  '''\n",
        "  cdata = tf.cast(data,tf.complex128) #tf complex 128 format\n",
        "  cdata = tf.signal.fft(cdata) #Fast Fourrie Transformation\n",
        "  cdata = cdata*tf.math.conj(cdata) #PSD Calculation\n",
        "  cdata = cdata[:len(cdata)//2] #Take only haf\n",
        "  cdata = cdata/tf.math.reduce_sum(cdata) #Normalização???\n",
        "  sh = cdata*tf.math.log(cdata) # Calculate Shannon entropy p1\n",
        "  sh = tf.math.real(tf.math.reduce_sum(sh)) #Calculate Shannon entropy p2\n",
        "  if norm == True: #Normalize?\n",
        "    norm = tf.cast(tf.math.log(1.0/tf.cast(len(cdata),tf.float64) ),tf.float64)\n",
        "    return cdata, sh/norm\n",
        "  else:\n",
        "    return cdata, -sh\n",
        "\n",
        "\n",
        "def fftfreq(n, d=1.0):\n",
        "    \"\"\"\n",
        "    Return the Discrete Fourier Transform sample frequencies.\n",
        "    The returned float array `f` contains the frequency bin centers in cycles\n",
        "    per unit of the sample spacing (with zero at the start).  For instance, if\n",
        "    the sample spacing is in seconds, then the frequency unit is cycles/second.\n",
        "    Given a window length `n` and a sample spacing `d`::\n",
        "      f = [0, 1, ...,   n/2-1,     -n/2, ..., -1] / (d*n)   if n is even\n",
        "      f = [0, 1, ..., (n-1)/2, -(n-1)/2, ..., -1] / (d*n)   if n is odd\n",
        "    Parameters\n",
        "    ----------\n",
        "    n : int\n",
        "        Window length.\n",
        "    d : scalar, optional\n",
        "        Sample spacing (inverse of the sampling rate). Defaults to 1.\n",
        "    Returns\n",
        "    -------\n",
        "    f : ndarray\n",
        "        Array of length `n` containing the sample frequencies.\n",
        "    Examples\n",
        "    --------\n",
        "    >>> signal = np.array([-2, 8, 6, 4, 1, 0, 3, 5], dtype=float)\n",
        "    >>> fourier = np.fft.fft(signal)\n",
        "    >>> n = signal.size\n",
        "    >>> timestep = 0.1\n",
        "    >>> freq = np.fft.fftfreq(n, d=timestep)\n",
        "    >>> freq\n",
        "    array([ 0.  ,  1.25,  2.5 , ..., -3.75, -2.5 , -1.25])\n",
        "    \"\"\"\n",
        "    if not isinstance(n, integer_types):\n",
        "        raise ValueError(\"n should be an integer\")\n",
        "    val = 1.0 / (n * d)\n",
        "    results = empty(n, int)\n",
        "    N = (n-1)//2 + 1\n",
        "    p1 = arange(0, N, dtype=int)\n",
        "    results[:N] = p1\n",
        "    p2 = arange(-(n//2), 0, dtype=int)\n",
        "    results[N:] = p2\n",
        "    return results * val\n",
        "\n",
        "\n",
        "def beta(data):\n",
        "  '''\n",
        "  Calculate de the PSD loglog power law index\n",
        "  '''\n",
        "  psd = tf.cast(data,tf.complex128) #tf complex 128 format\n",
        "  psd = tf.signal.fft(psd) #FFT me da um vetor complexo\n",
        "  psd = psd*tf.math.conj(psd) #Complexo conjudado \n",
        "  print(len(data))\n",
        "  freq = np.fft.fftfreq(1024) #mede as frequencias da tranformada de four\n",
        "  #freq = fftfreq(1024) #mede as frequencias da tranformada de four\n",
        "  n = len(data)//2 #ponto de conte. Nesse caso é pela metade\n",
        "  psd = psd[1:n] #Só quero metade dos dados, menos o 1 pq ele estava sendo inf\n",
        "  freq =  tf.convert_to_tensor(freq[1:n]) #converte para um tensor do tf\n",
        "  psd = tf.cast(tf.math.log(psd), tf.float64) #convert para log, e só pega o real \n",
        "  freq = tf.cast(tf.math.log(freq),tf.float64) #mesma coisa, só que frequencia\n",
        "  beta, _ =np.polyfit(np.array(freq),np.array(psd),deg=1) #ajuste linear\n",
        "  return -beta #partiu para o abraço\n",
        "\n",
        "def diffBeta(d1,d2):\n",
        "  return (beta(d1)-beta(d2))**2\n",
        "\n",
        "def create_dataset(dataset, window_in=10,window_ou=10,window_next=1):\n",
        "\t'''\n",
        "  This function will contain two vectors, dataX and dataY, the dataX will contain a set of numbers within the time series\n",
        "  and the dataY will be its posterior value\n",
        "  For example:\n",
        "  list = [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15]\n",
        "  if the window_in is equal to 3 anf window_ou equato to 2 we will have\n",
        "  dataX[0] = [0,1,2] ; dataY[0] = [3,4]\n",
        "  dataX[1] = [1,2,3] ; dataY[1] = [4,5]\n",
        "  dataX[2] = [2,3,4] ; dataY[2] = [5,6]\n",
        "  dataX[3] = [3,4,5] ; dataY[3] = [6,7]\n",
        "  window_next will, shift the data ex for 4:\n",
        "  dataX[0] = [0,1,2] ; dataY[0] = [3,4]\n",
        "  dataX[1] = [3,4,5] ; dataY[1] = [6,7]\n",
        "  dataX[2] = [7,8,9] ; dataY[2] = [10,11]\n",
        "  '''\n",
        "\tdataset = dataset.reshape(len(dataset),1)\n",
        "\tdataX, dataY = [], []\n",
        "\tfor i in range(0,len(dataset)-window_in-window_ou+1,window_next):\n",
        "\t\tdataX.append(dataset[i:(i+window_in), 0])\n",
        "\t\tdataY.append(dataset[i + window_in:i + window_in + window_ou, 0])\n",
        "\treturn np.array(dataX), np.array(dataY)  \n",
        "\n",
        "def plot_test(x_,y_):\n",
        "  empty = np.empty_like(x_)\n",
        "  empty[:] = np.nan\n",
        "  y2 = np.append(empty,y_)\n",
        "  plt.plot(x_)\n",
        "  plt.plot(y2)\n",
        "  #plt.show() "
      ],
      "metadata": {
        "id": "_Fjlz0ztMiRW"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.fft.fftfreq(1024)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gN-1f6zksREe",
        "outputId": "e730cdc4-3a1f-48d0-d3a0-5258b757c10f"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0.        ,  0.00097656,  0.00195312, ..., -0.00292969,\n",
              "       -0.00195312, -0.00097656])"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Generation"
      ],
      "metadata": {
        "id": "4o1tUbI7dF2A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "jump = 4\n",
        "2**(15-jump)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UrA_LG6heGnM",
        "outputId": "d6a713c8-2a5a-431e-88c9-3d844645ecee"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2048"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bet = 0\n",
        "samples = 2**15\n",
        "win_in = 1024\n",
        "win_ou = 1024\n",
        "jump = 2**4\n",
        "\n",
        "dat = cn.powerlaw_psd_gaussian(bet, samples)\n",
        "trainX,trainY = create_dataset(dat,win_in,win_ou,jump)\n"
      ],
      "metadata": {
        "id": "4f212gm1VYhY"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainX = trainX.reshape(trainX.shape[0],trainX.shape[1],1)\n",
        "#trainY = trainY.reshape(np.axi,trainY.shape[1],trainY.shape[0])"
      ],
      "metadata": {
        "id": "XPQX1aTgefb7"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainX.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6gGDznkPfzjJ",
        "outputId": "e7440fd6-35b6-4cbb-d4cc-8d3921dc4167"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1921, 1024, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model"
      ],
      "metadata": {
        "id": "EVFvoPZ-dDrZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Paramenters \n",
        "epochs = 3\n",
        "batch_size = 256#len(trainX)# 256#\n",
        "model_code = 'test'#All_layers_Bacth256'\n",
        "n_1 = 64#10#int(look_back*100)\n",
        "n_2 = 64#int(look_back*100)\n",
        "n_3 = 64 #int(look_back*1e-1)\n",
        "n_4 = 64#10#int(look_back*1e-1)"
      ],
      "metadata": {
        "id": "1C1VLnmZdXRT"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "diffBeta(trainX[0],trainY[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iLrHDWJIqT6E",
        "outputId": "36c55197-9807-4a5f-fe5a-72fa75225c76"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Teste 1024\n",
            "1024\n",
            "1024\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.0049201])"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.compat.v1.enable_eager_execution()\n",
        "\n",
        "star_RNN = time.time()\n",
        "model_RNN = Sequential()\n",
        "model_RNN.add(SimpleRNN(n_1, return_sequences=True,input_shape=[win_in,1] ))\n",
        "model_RNN.add(SimpleRNN(n_4))\n",
        "model_RNN.add(Dense(win_ou))\n",
        "model_RNN.compile(loss=diffBeta, optimizer='adam',metrics=['mse'])\n",
        "history_RNN = model_RNN.fit(trainX, trainY, epochs=epochs, batch_size=batch_size, verbose=1,validation_split=0.7)"
      ],
      "metadata": {
        "id": "HvCx8Q5FgQ9Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_ZQGbJW1enub"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}